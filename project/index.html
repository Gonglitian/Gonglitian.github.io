<!DOCTYPE html><html lang="en" class="scroll-smooth"><head><meta charSet="utf-8"/><meta name="viewport" content="width=device-width, initial-scale=1"/><link rel="stylesheet" href="/_next/static/css/78600482fd656caf.css" data-precedence="next"/><link rel="preload" as="script" fetchPriority="low" href="/_next/static/chunks/webpack-679b75d1c4c2027c.js"/><script src="/_next/static/chunks/4bd1b696-70b6d399998de86a.js" async=""></script><script src="/_next/static/chunks/684-50096e198fb40285.js" async=""></script><script src="/_next/static/chunks/main-app-c2e8e391d77dc171.js" async=""></script><script src="/_next/static/chunks/161-c92285856b08f5b4.js" async=""></script><script src="/_next/static/chunks/874-196dbf0660d69360.js" async=""></script><script src="/_next/static/chunks/560-83a075b4e219aa9a.js" async=""></script><script src="/_next/static/chunks/app/layout-2e0b700e04730bd2.js" async=""></script><script src="/_next/static/chunks/299-532582fc3fb7f62f.js" async=""></script><script src="/_next/static/chunks/748-5cfa0c6e1546bcb7.js" async=""></script><script src="/_next/static/chunks/app/%5Bslug%5D/page-554505d753047240.js" async=""></script><link rel="icon" href="/favicon.svg" type="image/svg+xml"/><link rel="dns-prefetch" href="https://google-fonts.jialeliu.com"/><link rel="preconnect" href="https://google-fonts.jialeliu.com" crossorigin=""/><link rel="stylesheet" href="https://google-fonts.jialeliu.com/css2?family=Inter:wght@300;400;500;600;700&amp;family=Crimson+Text:ital,wght@0,400;0,600;1,400&amp;display=swap"/><script>
              try {
                const theme = localStorage.getItem('theme-storage');
                const parsed = theme ? JSON.parse(theme) : null;
                const setting = parsed?.state?.theme || 'system';
                const prefersDark = typeof window !== 'undefined' && window.matchMedia && window.matchMedia('(prefers-color-scheme: dark)').matches;
                const effective = setting === 'dark' ? 'dark' : (setting === 'light' ? 'light' : (prefersDark ? 'dark' : 'light'));
                var root = document.documentElement;
                root.classList.add(effective);
                root.setAttribute('data-theme', effective);
              } catch (e) {
                var root = document.documentElement;
                root.classList.add('light');
                root.setAttribute('data-theme', 'light');
              }
            </script><title>Projects | Litian Gong</title><meta name="description" content="Research projects and work I have been involved in."/><meta name="author" content="Litian Gong"/><meta name="keywords" content="Litian Gong,PhD,Research,University of California, Riverside"/><meta name="creator" content="Litian Gong"/><meta name="publisher" content="Litian Gong"/><meta property="og:title" content="Litian Gong"/><meta property="og:description" content="Master&#x27;s student in Electrical Engineering at UC Riverside, researching embodied AI and robot learning."/><meta property="og:site_name" content="Litian Gong&#x27;s Academic Website"/><meta property="og:locale" content="en_US"/><meta property="og:type" content="website"/><meta name="twitter:card" content="summary"/><meta name="twitter:title" content="Litian Gong"/><meta name="twitter:description" content="Master&#x27;s student in Electrical Engineering at UC Riverside, researching embodied AI and robot learning."/><link rel="icon" href="/favicon.svg"/><script>document.querySelectorAll('body link[rel="icon"], body link[rel="apple-touch-icon"]').forEach(el => document.head.appendChild(el))</script><script src="/_next/static/chunks/polyfills-42372ed130431b0a.js" noModule=""></script></head><body class="font-sans antialiased"><div style="visibility:hidden"><nav class="fixed top-0 left-0 right-0 z-50" data-headlessui-state=""><div class="transition-all duration-300 ease-out bg-transparent" style="transform:translateY(-100px)"><div class="max-w-7xl mx-auto px-4 sm:px-6 lg:px-8"><div class="flex justify-between items-center h-16 lg:h-20"><div class="flex-shrink-0" tabindex="0"><a class="text-xl lg:text-2xl font-serif font-semibold text-primary hover:text-accent transition-colors duration-200" href="/">Litian Gong</a></div><div class="hidden lg:block"><div class="ml-10 flex items-center space-x-8"><div class="flex items-baseline space-x-8"><a class="relative px-3 py-2 text-sm font-medium transition-all duration-200 rounded hover:bg-accent/10 hover:shadow-sm text-neutral-600 hover:text-primary" href="/"><span class="relative z-10">About</span></a><a class="relative px-3 py-2 text-sm font-medium transition-all duration-200 rounded hover:bg-accent/10 hover:shadow-sm text-neutral-600 hover:text-primary" href="/publications/"><span class="relative z-10">Publications</span></a><a class="relative px-3 py-2 text-sm font-medium transition-all duration-200 rounded hover:bg-accent/10 hover:shadow-sm text-primary" href="/project/"><span class="relative z-10">Projects</span><div class="absolute inset-0 bg-accent/10 rounded-lg"></div></a><a class="relative px-3 py-2 text-sm font-medium transition-all duration-200 rounded hover:bg-accent/10 hover:shadow-sm text-neutral-600 hover:text-primary" href="/awards/"><span class="relative z-10">Awards</span></a><a class="relative px-3 py-2 text-sm font-medium transition-all duration-200 rounded hover:bg-accent/10 hover:shadow-sm text-neutral-600 hover:text-primary" href="/services/"><span class="relative z-10">Services</span></a><a class="relative px-3 py-2 text-sm font-medium transition-all duration-200 rounded hover:bg-accent/10 hover:shadow-sm text-neutral-600 hover:text-primary" href="/cv/"><span class="relative z-10">CV</span></a></div><div class="flex items-center justify-center w-10 h-10 rounded-lg border border-neutral-200 dark:border-[rgba(148,163,184,0.24)] bg-background dark:bg-neutral-800"><div class="w-4 h-4 rounded-full bg-neutral-300 animate-pulse"></div></div></div></div><div class="lg:hidden flex items-center space-x-2"><div class="flex items-center justify-center w-10 h-10 rounded-lg border border-neutral-200 dark:border-[rgba(148,163,184,0.24)] bg-background dark:bg-neutral-800"><div class="w-4 h-4 rounded-full bg-neutral-300 animate-pulse"></div></div><button class="inline-flex items-center justify-center p-2 rounded-md text-neutral-600 hover:text-primary hover:bg-neutral-100 dark:hover:bg-neutral-800 focus:outline-none focus:ring-2 focus:ring-inset focus:ring-accent transition-colors duration-200" id="headlessui-disclosure-button-Â«R5pdbÂ»" type="button" aria-expanded="false" data-headlessui-state=""><span class="sr-only">Open main menu</span><div><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" class="block h-6 w-6"><path stroke-linecap="round" stroke-linejoin="round" d="M3.75 6.75h16.5M3.75 12h16.5m-16.5 5.25h16.5"></path></svg></div></button></div></div></div></div></nav><main class="min-h-screen pt-16 lg:pt-20"><div class="max-w-7xl mx-auto px-4 sm:px-6 lg:px-8 py-12"><div style="opacity:0;transform:translateY(20px)"><div class="mb-8"><h1 class="text-4xl font-serif font-bold text-primary mb-4">Projects</h1><p class="text-lg text-neutral-600 dark:text-neutral-500 max-w-2xl">Research projects and work I have been involved in.</p></div><div class="grid gap-6"><div class="bg-white dark:bg-neutral-900 p-6 rounded-xl shadow-sm border border-neutral-200 dark:border-neutral-800 hover:shadow-lg transition-all duration-200 hover:scale-[1.01]" style="opacity:0;transform:translateY(20px)"><div class="flex flex-col md:flex-row gap-4"><div class="w-full md:w-48 flex-shrink-0 relative z-0"><div class="aspect-square relative rounded-lg overflow-visible dark:bg-neutral-700 group cursor-pointer"><img alt="AutoFocus-IL" loading="lazy" decoding="async" data-nimg="fill" class="object-contain p-2 transition-all duration-300 ease-in-out group-hover:scale-150 group-hover:z-[100] group-hover:shadow-2xl rounded-lg" style="position:absolute;height:100%;width:100%;left:0;top:0;right:0;bottom:0;color:transparent" src="/papers/autofocus-il.png"/></div></div><div class="flex-grow"><div class="flex justify-between items-start mb-2"><h3 class="text-xl font-semibold text-primary">AutoFocus-IL</h3><span class="text-sm text-neutral-500 font-medium bg-neutral-100 dark:bg-neutral-800 px-2 py-1 rounded">2025</span></div><p class="text-base text-accent font-medium mb-3">VLM-based Visual Imitation Learning</p><p class="text-base text-neutral-600 dark:text-neutral-500 leading-relaxed mb-3">A vision-language model guided saliency framework for data-efficient visual imitation learning. The system automatically identifies task-relevant visual cues without requiring human gaze supervision, improving policy robustness in both simulation and real-robot experiments.</p><div class="flex flex-wrap gap-2 mb-3"><a href="https://autofocus-il.github.io/" target="_blank" rel="noopener noreferrer" class="inline-flex items-center px-3 py-1 rounded-md text-xs font-medium bg-neutral-100 dark:bg-neutral-800 text-neutral-700 dark:text-neutral-300 hover:bg-accent hover:text-white transition-colors"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" class="h-3 w-3 mr-1.5"><path stroke-linecap="round" stroke-linejoin="round" d="M12 21a9.004 9.004 0 0 0 8.716-6.747M12 21a9.004 9.004 0 0 1-8.716-6.747M12 21c2.485 0 4.5-4.03 4.5-9S14.485 3 12 3m0 18c-2.485 0-4.5-4.03-4.5-9S9.515 3 12 3m0 0a8.997 8.997 0 0 1 7.843 4.582M12 3a8.997 8.997 0 0 0-7.843 4.582m15.686 0A11.953 11.953 0 0 1 12 10.5c-2.998 0-5.74-1.1-7.843-2.918m15.686 0A8.959 8.959 0 0 1 21 12c0 .778-.099 1.533-.284 2.253m0 0A17.919 17.919 0 0 1 12 16.5c-3.162 0-6.133-.815-8.716-2.247m0 0A9.015 9.015 0 0 1 3 12c0-1.605.42-3.113 1.157-4.418"></path></svg>Demo</a><a href="https://github.com/autofocus-il/autofocus-il" target="_blank" rel="noopener noreferrer" class="inline-flex items-center px-3 py-1 rounded-md text-xs font-medium bg-neutral-100 dark:bg-neutral-800 text-neutral-700 dark:text-neutral-300 hover:bg-accent hover:text-white transition-colors"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" class="h-3 w-3 mr-1.5"><path stroke-linecap="round" stroke-linejoin="round" d="M17.25 6.75 22.5 12l-5.25 5.25m-10.5 0L1.5 12l5.25-5.25m7.5-3-4.5 16.5"></path></svg>Code</a><a href="https://arxiv.org/abs/2511.18617" target="_blank" rel="noopener noreferrer" class="inline-flex items-center px-3 py-1 rounded-md text-xs font-medium bg-neutral-100 dark:bg-neutral-800 text-neutral-700 dark:text-neutral-300 hover:bg-accent hover:text-white transition-colors"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" class="h-3 w-3 mr-1.5"><path stroke-linecap="round" stroke-linejoin="round" d="M19.5 14.25v-2.625a3.375 3.375 0 0 0-3.375-3.375h-1.5A1.125 1.125 0 0 1 13.5 7.125v-1.5a3.375 3.375 0 0 0-3.375-3.375H8.25m0 12.75h7.5m-7.5 3H12M10.5 2.25H5.625c-.621 0-1.125.504-1.125 1.125v17.25c0 .621.504 1.125 1.125 1.125h12.75c.621 0 1.125-.504 1.125-1.125V11.25a9 9 0 0 0-9-9Z"></path></svg>Paper</a></div><div class="flex flex-wrap gap-2 mt-4"><span class="text-xs text-neutral-500 bg-neutral-50 dark:bg-neutral-800/50 px-2 py-1 rounded border border-neutral-100 dark:border-neutral-800">Imitation Learning</span><span class="text-xs text-neutral-500 bg-neutral-50 dark:bg-neutral-800/50 px-2 py-1 rounded border border-neutral-100 dark:border-neutral-800">VLMs</span><span class="text-xs text-neutral-500 bg-neutral-50 dark:bg-neutral-800/50 px-2 py-1 rounded border border-neutral-100 dark:border-neutral-800">Robot Learning</span><span class="text-xs text-neutral-500 bg-neutral-50 dark:bg-neutral-800/50 px-2 py-1 rounded border border-neutral-100 dark:border-neutral-800">PyTorch</span></div></div></div></div><div class="bg-white dark:bg-neutral-900 p-6 rounded-xl shadow-sm border border-neutral-200 dark:border-neutral-800 hover:shadow-lg transition-all duration-200 hover:scale-[1.01]" style="opacity:0;transform:translateY(20px)"><div class="flex flex-col md:flex-row gap-4"><div class="w-full md:w-48 flex-shrink-0 relative z-0"><div class="aspect-square relative rounded-lg overflow-visible dark:bg-neutral-700 group cursor-pointer"><img alt="ORIC Benchmark" loading="lazy" decoding="async" data-nimg="fill" class="object-contain p-2 transition-all duration-300 ease-in-out group-hover:scale-150 group-hover:z-[100] group-hover:shadow-2xl rounded-lg" style="position:absolute;height:100%;width:100%;left:0;top:0;right:0;bottom:0;color:transparent" src="/papers/oric.png"/></div></div><div class="flex-grow"><div class="flex justify-between items-start mb-2"><h3 class="text-xl font-semibold text-primary">ORIC Benchmark</h3><span class="text-sm text-neutral-500 font-medium bg-neutral-100 dark:bg-neutral-800 px-2 py-1 rounded">2025</span></div><p class="text-base text-accent font-medium mb-3">Object Recognition in Incongruous Contexts</p><p class="text-base text-neutral-600 dark:text-neutral-500 leading-relaxed mb-3">A comprehensive benchmark for evaluating object recognition capabilities of large vision-language models when objects appear in unexpected or unusual settings. The benchmark tests robustness and generalization of VLMs across diverse contextual scenarios.</p><div class="flex flex-wrap gap-2 mb-3"><a href="https://github.com/ZhaoyangLi-1/ORIC" target="_blank" rel="noopener noreferrer" class="inline-flex items-center px-3 py-1 rounded-md text-xs font-medium bg-neutral-100 dark:bg-neutral-800 text-neutral-700 dark:text-neutral-300 hover:bg-accent hover:text-white transition-colors"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" class="h-3 w-3 mr-1.5"><path stroke-linecap="round" stroke-linejoin="round" d="M17.25 6.75 22.5 12l-5.25 5.25m-10.5 0L1.5 12l5.25-5.25m7.5-3-4.5 16.5"></path></svg>Code</a><a href="https://arxiv.org/abs/2509.15695" target="_blank" rel="noopener noreferrer" class="inline-flex items-center px-3 py-1 rounded-md text-xs font-medium bg-neutral-100 dark:bg-neutral-800 text-neutral-700 dark:text-neutral-300 hover:bg-accent hover:text-white transition-colors"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" class="h-3 w-3 mr-1.5"><path stroke-linecap="round" stroke-linejoin="round" d="M19.5 14.25v-2.625a3.375 3.375 0 0 0-3.375-3.375h-1.5A1.125 1.125 0 0 1 13.5 7.125v-1.5a3.375 3.375 0 0 0-3.375-3.375H8.25m0 12.75h7.5m-7.5 3H12M10.5 2.25H5.625c-.621 0-1.125.504-1.125 1.125v17.25c0 .621.504 1.125 1.125 1.125h12.75c.621 0 1.125-.504 1.125-1.125V11.25a9 9 0 0 0-9-9Z"></path></svg>Paper</a></div><div class="flex flex-wrap gap-2 mt-4"><span class="text-xs text-neutral-500 bg-neutral-50 dark:bg-neutral-800/50 px-2 py-1 rounded border border-neutral-100 dark:border-neutral-800">Computer Vision</span><span class="text-xs text-neutral-500 bg-neutral-50 dark:bg-neutral-800/50 px-2 py-1 rounded border border-neutral-100 dark:border-neutral-800">VLMs</span><span class="text-xs text-neutral-500 bg-neutral-50 dark:bg-neutral-800/50 px-2 py-1 rounded border border-neutral-100 dark:border-neutral-800">Benchmarking</span><span class="text-xs text-neutral-500 bg-neutral-50 dark:bg-neutral-800/50 px-2 py-1 rounded border border-neutral-100 dark:border-neutral-800">Evaluation</span></div></div></div></div><div class="bg-white dark:bg-neutral-900 p-6 rounded-xl shadow-sm border border-neutral-200 dark:border-neutral-800 hover:shadow-lg transition-all duration-200 hover:scale-[1.01]" style="opacity:0;transform:translateY(20px)"><div class="flex flex-col md:flex-row gap-4"><div class="w-full md:w-48 flex-shrink-0 relative z-0"><div class="aspect-square relative rounded-lg overflow-visible dark:bg-neutral-700 group cursor-pointer"><img alt="Robotic Manipulation Framework" loading="lazy" decoding="async" data-nimg="fill" class="object-contain p-2 transition-all duration-300 ease-in-out group-hover:scale-150 group-hover:z-[100] group-hover:shadow-2xl rounded-lg" style="position:absolute;height:100%;width:100%;left:0;top:0;right:0;bottom:0;color:transparent" src="/papers/example.png"/></div></div><div class="flex-grow"><div class="flex justify-between items-start mb-2"><h3 class="text-xl font-semibold text-primary">Robotic Manipulation Framework</h3><span class="text-sm text-neutral-500 font-medium bg-neutral-100 dark:bg-neutral-800 px-2 py-1 rounded">2024</span></div><p class="text-base text-accent font-medium mb-3">Sim-to-Real Transfer Learning</p><p class="text-base text-neutral-600 dark:text-neutral-500 leading-relaxed mb-3">A scalable framework for training robotic manipulation policies using imitation learning and reinforcement learning. The system enables efficient sim-to-real transfer for complex manipulation tasks in household environments.</p><div class="flex flex-wrap gap-2 mb-3"><a href="https://example-demo.com" target="_blank" rel="noopener noreferrer" class="inline-flex items-center px-3 py-1 rounded-md text-xs font-medium bg-neutral-100 dark:bg-neutral-800 text-neutral-700 dark:text-neutral-300 hover:bg-accent hover:text-white transition-colors"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" class="h-3 w-3 mr-1.5"><path stroke-linecap="round" stroke-linejoin="round" d="M12 21a9.004 9.004 0 0 0 8.716-6.747M12 21a9.004 9.004 0 0 1-8.716-6.747M12 21c2.485 0 4.5-4.03 4.5-9S14.485 3 12 3m0 18c-2.485 0-4.5-4.03-4.5-9S9.515 3 12 3m0 0a8.997 8.997 0 0 1 7.843 4.582M12 3a8.997 8.997 0 0 0-7.843 4.582m15.686 0A11.953 11.953 0 0 1 12 10.5c-2.998 0-5.74-1.1-7.843-2.918m15.686 0A8.959 8.959 0 0 1 21 12c0 .778-.099 1.533-.284 2.253m0 0A17.919 17.919 0 0 1 12 16.5c-3.162 0-6.133-.815-8.716-2.247m0 0A9.015 9.015 0 0 1 3 12c0-1.605.42-3.113 1.157-4.418"></path></svg>Demo</a><a href="https://github.com/example/repo" target="_blank" rel="noopener noreferrer" class="inline-flex items-center px-3 py-1 rounded-md text-xs font-medium bg-neutral-100 dark:bg-neutral-800 text-neutral-700 dark:text-neutral-300 hover:bg-accent hover:text-white transition-colors"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" class="h-3 w-3 mr-1.5"><path stroke-linecap="round" stroke-linejoin="round" d="M17.25 6.75 22.5 12l-5.25 5.25m-10.5 0L1.5 12l5.25-5.25m7.5-3-4.5 16.5"></path></svg>Code</a></div><div class="flex flex-wrap gap-2 mt-4"><span class="text-xs text-neutral-500 bg-neutral-50 dark:bg-neutral-800/50 px-2 py-1 rounded border border-neutral-100 dark:border-neutral-800">Robotics</span><span class="text-xs text-neutral-500 bg-neutral-50 dark:bg-neutral-800/50 px-2 py-1 rounded border border-neutral-100 dark:border-neutral-800">RL</span><span class="text-xs text-neutral-500 bg-neutral-50 dark:bg-neutral-800/50 px-2 py-1 rounded border border-neutral-100 dark:border-neutral-800">Sim-to-Real</span><span class="text-xs text-neutral-500 bg-neutral-50 dark:bg-neutral-800/50 px-2 py-1 rounded border border-neutral-100 dark:border-neutral-800">Manipulation</span></div></div></div></div></div></div></div><!--$--><!--/$--><!--$--><!--/$--></main><footer class="border-t border-neutral-200/50 bg-neutral-50/50 dark:bg-neutral-900/50 dark:border-neutral-700/50"><div class="max-w-6xl mx-auto px-4 sm:px-6 lg:px-8 py-6"><div class="flex flex-col sm:flex-row justify-between items-center gap-2"><p class="text-xs text-neutral-500">Last updated: <!-- -->November 27, 2025</p><p class="text-xs text-neutral-500 flex items-center"><a href="https://github.com/xyjoey/PRISM" target="_blank" rel="noopener noreferrer">Built with PRISM</a><span class="ml-2">ðŸš€</span></p></div></div></footer></div><script src="/_next/static/chunks/webpack-679b75d1c4c2027c.js" async=""></script><script>(self.__next_f=self.__next_f||[]).push([0])</script><script>self.__next_f.push([1,"1:\"$Sreact.fragment\"\n2:I[3719,[\"161\",\"static/chunks/161-c92285856b08f5b4.js\",\"874\",\"static/chunks/874-196dbf0660d69360.js\",\"560\",\"static/chunks/560-83a075b4e219aa9a.js\",\"177\",\"static/chunks/app/layout-2e0b700e04730bd2.js\"],\"ThemeProvider\"]\n3:I[768,[\"161\",\"static/chunks/161-c92285856b08f5b4.js\",\"874\",\"static/chunks/874-196dbf0660d69360.js\",\"560\",\"static/chunks/560-83a075b4e219aa9a.js\",\"177\",\"static/chunks/app/layout-2e0b700e04730bd2.js\"],\"default\"]\n4:I[7555,[],\"\"]\n5:I[1295,[],\"\"]\n6:I[2548,[\"161\",\"static/chunks/161-c92285856b08f5b4.js\",\"874\",\"static/chunks/874-196dbf0660d69360.js\",\"560\",\"static/chunks/560-83a075b4e219aa9a.js\",\"177\",\"static/chunks/app/layout-2e0b700e04730bd2.js\"],\"default\"]\n8:I[9665,[],\"MetadataBoundary\"]\na:I[9665,[],\"OutletBoundary\"]\nd:I[4911,[],\"AsyncMetadataOutlet\"]\nf:I[9665,[],\"ViewportBoundary\"]\n11:I[6614,[],\"\"]\n:HL[\"/_next/static/css/78600482fd656caf.css\",\"style\"]\n"])</script><script>self.__next_f.push([1,"0:{\"P\":null,\"b\":\"4cwngSQR6fMrsPtqBzbpa\",\"p\":\"\",\"c\":[\"\",\"project\",\"\"],\"i\":false,\"f\":[[[\"\",{\"children\":[[\"slug\",\"project\",\"d\"],{\"children\":[\"__PAGE__\",{}]}]},\"$undefined\",\"$undefined\",true],[\"\",[\"$\",\"$1\",\"c\",{\"children\":[[[\"$\",\"link\",\"0\",{\"rel\":\"stylesheet\",\"href\":\"/_next/static/css/78600482fd656caf.css\",\"precedence\":\"next\",\"crossOrigin\":\"$undefined\",\"nonce\":\"$undefined\"}]],[\"$\",\"html\",null,{\"lang\":\"en\",\"className\":\"scroll-smooth\",\"suppressHydrationWarning\":true,\"children\":[[\"$\",\"head\",null,{\"children\":[[\"$\",\"link\",null,{\"rel\":\"icon\",\"href\":\"/favicon.svg\",\"type\":\"image/svg+xml\"}],[\"$\",\"link\",null,{\"rel\":\"dns-prefetch\",\"href\":\"https://google-fonts.jialeliu.com\"}],[\"$\",\"link\",null,{\"rel\":\"preconnect\",\"href\":\"https://google-fonts.jialeliu.com\",\"crossOrigin\":\"\"}],[\"$\",\"link\",null,{\"rel\":\"stylesheet\",\"href\":\"https://google-fonts.jialeliu.com/css2?family=Inter:wght@300;400;500;600;700\u0026family=Crimson+Text:ital,wght@0,400;0,600;1,400\u0026display=swap\"}],[\"$\",\"script\",null,{\"dangerouslySetInnerHTML\":{\"__html\":\"\\n              try {\\n                const theme = localStorage.getItem('theme-storage');\\n                const parsed = theme ? JSON.parse(theme) : null;\\n                const setting = parsed?.state?.theme || 'system';\\n                const prefersDark = typeof window !== 'undefined' \u0026\u0026 window.matchMedia \u0026\u0026 window.matchMedia('(prefers-color-scheme: dark)').matches;\\n                const effective = setting === 'dark' ? 'dark' : (setting === 'light' ? 'light' : (prefersDark ? 'dark' : 'light'));\\n                var root = document.documentElement;\\n                root.classList.add(effective);\\n                root.setAttribute('data-theme', effective);\\n              } catch (e) {\\n                var root = document.documentElement;\\n                root.classList.add('light');\\n                root.setAttribute('data-theme', 'light');\\n              }\\n            \"}}]]}],[\"$\",\"body\",null,{\"className\":\"font-sans antialiased\",\"children\":[\"$\",\"$L2\",null,{\"children\":[[\"$\",\"$L3\",null,{\"items\":[{\"title\":\"About\",\"type\":\"page\",\"target\":\"about\",\"href\":\"/\"},{\"title\":\"Publications\",\"type\":\"page\",\"target\":\"publications\",\"href\":\"/publications\"},{\"title\":\"Projects\",\"type\":\"page\",\"target\":\"project\",\"href\":\"/project\"},{\"title\":\"Awards\",\"type\":\"page\",\"target\":\"awards\",\"href\":\"/awards\"},{\"title\":\"Services\",\"type\":\"page\",\"target\":\"services\",\"href\":\"/services\"},{\"title\":\"CV\",\"type\":\"page\",\"target\":\"cv\",\"href\":\"/cv\"}],\"siteTitle\":\"Litian Gong\",\"enableOnePageMode\":false}],[\"$\",\"main\",null,{\"className\":\"min-h-screen pt-16 lg:pt-20\",\"children\":[\"$\",\"$L4\",null,{\"parallelRouterKey\":\"children\",\"error\":\"$undefined\",\"errorStyles\":\"$undefined\",\"errorScripts\":\"$undefined\",\"template\":[\"$\",\"$L5\",null,{}],\"templateStyles\":\"$undefined\",\"templateScripts\":\"$undefined\",\"notFound\":[[[\"$\",\"title\",null,{\"children\":\"404: This page could not be found.\"}],[\"$\",\"div\",null,{\"style\":{\"fontFamily\":\"system-ui,\\\"Segoe UI\\\",Roboto,Helvetica,Arial,sans-serif,\\\"Apple Color Emoji\\\",\\\"Segoe UI Emoji\\\"\",\"height\":\"100vh\",\"textAlign\":\"center\",\"display\":\"flex\",\"flexDirection\":\"column\",\"alignItems\":\"center\",\"justifyContent\":\"center\"},\"children\":[\"$\",\"div\",null,{\"children\":[[\"$\",\"style\",null,{\"dangerouslySetInnerHTML\":{\"__html\":\"body{color:#000;background:#fff;margin:0}.next-error-h1{border-right:1px solid rgba(0,0,0,.3)}@media (prefers-color-scheme:dark){body{color:#fff;background:#000}.next-error-h1{border-right:1px solid rgba(255,255,255,.3)}}\"}}],[\"$\",\"h1\",null,{\"className\":\"next-error-h1\",\"style\":{\"display\":\"inline-block\",\"margin\":\"0 20px 0 0\",\"padding\":\"0 23px 0 0\",\"fontSize\":24,\"fontWeight\":500,\"verticalAlign\":\"top\",\"lineHeight\":\"49px\"},\"children\":404}],[\"$\",\"div\",null,{\"style\":{\"display\":\"inline-block\"},\"children\":[\"$\",\"h2\",null,{\"style\":{\"fontSize\":14,\"fontWeight\":400,\"lineHeight\":\"49px\",\"margin\":0},\"children\":\"This page could not be found.\"}]}]]}]}]],[]],\"forbidden\":\"$undefined\",\"unauthorized\":\"$undefined\"}]}],[\"$\",\"$L6\",null,{\"lastUpdated\":\"November 27, 2025\"}]]}]}]]}]]}],{\"children\":[[\"slug\",\"project\",\"d\"],[\"$\",\"$1\",\"c\",{\"children\":[null,[\"$\",\"$L4\",null,{\"parallelRouterKey\":\"children\",\"error\":\"$undefined\",\"errorStyles\":\"$undefined\",\"errorScripts\":\"$undefined\",\"template\":[\"$\",\"$L5\",null,{}],\"templateStyles\":\"$undefined\",\"templateScripts\":\"$undefined\",\"notFound\":\"$undefined\",\"forbidden\":\"$undefined\",\"unauthorized\":\"$undefined\"}]]}],{\"children\":[\"__PAGE__\",[\"$\",\"$1\",\"c\",{\"children\":[\"$L7\",[\"$\",\"$L8\",null,{\"children\":\"$L9\"}],null,[\"$\",\"$La\",null,{\"children\":[\"$Lb\",\"$Lc\",[\"$\",\"$Ld\",null,{\"promise\":\"$@e\"}]]}]]}],{},null,false]},null,false]},null,false],[\"$\",\"$1\",\"h\",{\"children\":[null,[\"$\",\"$1\",\"Nwj5CcK1D6TF3o8PbE4cn\",{\"children\":[[\"$\",\"$Lf\",null,{\"children\":\"$L10\"}],null]}],null]}],false]],\"m\":\"$undefined\",\"G\":[\"$11\",\"$undefined\"],\"s\":false,\"S\":true}\n"])</script><script>self.__next_f.push([1,"12:\"$Sreact.suspense\"\n13:I[4911,[],\"AsyncMetadata\"]\n15:I[3684,[\"161\",\"static/chunks/161-c92285856b08f5b4.js\",\"299\",\"static/chunks/299-532582fc3fb7f62f.js\",\"748\",\"static/chunks/748-5cfa0c6e1546bcb7.js\",\"182\",\"static/chunks/app/%5Bslug%5D/page-554505d753047240.js\"],\"default\"]\n9:[\"$\",\"$12\",null,{\"fallback\":null,\"children\":[\"$\",\"$L13\",null,{\"promise\":\"$@14\"}]}]\n7:[\"$\",\"div\",null,{\"className\":\"max-w-7xl mx-auto px-4 sm:px-6 lg:px-8 py-12\",\"children\":[false,false,[\"$\",\"$L15\",null,{\"config\":{\"type\":\"card\",\"title\":\"Projects\",\"description\":\"Research projects and work I have been involved in.\",\"items\":[{\"title\":\"AutoFocus-IL\",\"subtitle\":\"VLM-based Visual Imitation Learning\",\"date\":\"2025\",\"content\":\"A vision-language model guided saliency framework for data-efficient visual imitation learning. The system automatically identifies task-relevant visual cues without requiring human gaze supervision, improving policy robustness in both simulation and real-robot experiments.\",\"image\":\"/papers/autofocus-il.png\",\"demo\":\"https://autofocus-il.github.io/\",\"code\":\"https://github.com/autofocus-il/autofocus-il\",\"paper\":\"https://arxiv.org/abs/2511.18617\",\"tags\":[\"Imitation Learning\",\"VLMs\",\"Robot Learning\",\"PyTorch\"]},{\"title\":\"ORIC Benchmark\",\"subtitle\":\"Object Recognition in Incongruous Contexts\",\"date\":\"2025\",\"content\":\"A comprehensive benchmark for evaluating object recognition capabilities of large vision-language models when objects appear in unexpected or unusual settings. The benchmark tests robustness and generalization of VLMs across diverse contextual scenarios.\",\"image\":\"/papers/oric.png\",\"code\":\"https://github.com/ZhaoyangLi-1/ORIC\",\"paper\":\"https://arxiv.org/abs/2509.15695\",\"tags\":[\"Computer Vision\",\"VLMs\",\"Benchmarking\",\"Evaluation\"]},{\"title\":\"Robotic Manipulation Framework\",\"subtitle\":\"Sim-to-Real Transfer Learning\",\"date\":\"2024\",\"content\":\"A scalable framework for training robotic manipulation policies using imitation learning and reinforcement learning. The system enables efficient sim-to-real transfer for complex manip"])</script><script>self.__next_f.push([1,"ulation tasks in household environments.\",\"image\":\"/papers/example.png\",\"demo\":\"https://example-demo.com\",\"code\":\"https://github.com/example/repo\",\"tags\":[\"Robotics\",\"RL\",\"Sim-to-Real\",\"Manipulation\"]}]}}]]}]\n"])</script><script>self.__next_f.push([1,"c:null\n"])</script><script>self.__next_f.push([1,"10:[[\"$\",\"meta\",\"0\",{\"charSet\":\"utf-8\"}],[\"$\",\"meta\",\"1\",{\"name\":\"viewport\",\"content\":\"width=device-width, initial-scale=1\"}]]\nb:null\n"])</script><script>self.__next_f.push([1,"14:{\"metadata\":[[\"$\",\"title\",\"0\",{\"children\":\"Projects | Litian Gong\"}],[\"$\",\"meta\",\"1\",{\"name\":\"description\",\"content\":\"Research projects and work I have been involved in.\"}],[\"$\",\"meta\",\"2\",{\"name\":\"author\",\"content\":\"Litian Gong\"}],[\"$\",\"meta\",\"3\",{\"name\":\"keywords\",\"content\":\"Litian Gong,PhD,Research,University of California, Riverside\"}],[\"$\",\"meta\",\"4\",{\"name\":\"creator\",\"content\":\"Litian Gong\"}],[\"$\",\"meta\",\"5\",{\"name\":\"publisher\",\"content\":\"Litian Gong\"}],[\"$\",\"meta\",\"6\",{\"property\":\"og:title\",\"content\":\"Litian Gong\"}],[\"$\",\"meta\",\"7\",{\"property\":\"og:description\",\"content\":\"Master's student in Electrical Engineering at UC Riverside, researching embodied AI and robot learning.\"}],[\"$\",\"meta\",\"8\",{\"property\":\"og:site_name\",\"content\":\"Litian Gong's Academic Website\"}],[\"$\",\"meta\",\"9\",{\"property\":\"og:locale\",\"content\":\"en_US\"}],[\"$\",\"meta\",\"10\",{\"property\":\"og:type\",\"content\":\"website\"}],[\"$\",\"meta\",\"11\",{\"name\":\"twitter:card\",\"content\":\"summary\"}],[\"$\",\"meta\",\"12\",{\"name\":\"twitter:title\",\"content\":\"Litian Gong\"}],[\"$\",\"meta\",\"13\",{\"name\":\"twitter:description\",\"content\":\"Master's student in Electrical Engineering at UC Riverside, researching embodied AI and robot learning.\"}],[\"$\",\"link\",\"14\",{\"rel\":\"icon\",\"href\":\"/favicon.svg\"}]],\"error\":null,\"digest\":\"$undefined\"}\ne:{\"metadata\":\"$14:metadata\",\"error\":null,\"digest\":\"$undefined\"}\n"])</script></body></html>
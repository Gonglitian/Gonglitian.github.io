<!DOCTYPE html><!--eJmAS4bSgJUF5hZPCAqBJ--><html lang="en" class="scroll-smooth"><head><meta charSet="utf-8"/><meta name="viewport" content="width=device-width, initial-scale=1"/><link rel="stylesheet" href="/_next/static/chunks/33fe7063c635829e.css" data-precedence="next"/><link rel="preload" as="script" fetchPriority="low" href="/_next/static/chunks/15f134bf6a9ffc0d.js"/><script src="/_next/static/chunks/41d269a0165a4c3d.js" async=""></script><script src="/_next/static/chunks/3a36804a2acfce4e.js" async=""></script><script src="/_next/static/chunks/e0c1dfd83bab4635.js" async=""></script><script src="/_next/static/chunks/12daa96885968840.js" async=""></script><script src="/_next/static/chunks/turbopack-189a22ee8b659e91.js" async=""></script><script src="/_next/static/chunks/9c176f40581040da.js" async=""></script><script src="/_next/static/chunks/96325a1b41eead81.js" async=""></script><script src="/_next/static/chunks/0137a57162bf5a2a.js" async=""></script><script src="/_next/static/chunks/ff1a16fafef87110.js" async=""></script><script src="/_next/static/chunks/694836347d1e5ef3.js" async=""></script><script src="/_next/static/chunks/9f31ef4f69e03b59.js" async=""></script><script src="/_next/static/chunks/35851190b7d05ff5.js" async=""></script><link rel="preload" href="https://google-fonts.jialeliu.com/css2?family=Inter:wght@300;400;500;600;700&amp;family=Crimson+Text:ital,wght@0,400;0,600;1,400&amp;display=swap" as="style"/><link rel="icon" href="/favicon.svg" type="image/svg+xml"/><link rel="dns-prefetch" href="https://google-fonts.jialeliu.com"/><link rel="preconnect" href="https://google-fonts.jialeliu.com" crossorigin=""/><title>Projects | Litian Gong</title><meta name="description" content="Research projects and work I have been involved in."/><meta name="author" content="Litian Gong"/><meta name="keywords" content="Litian Gong,PhD,Research,University of California, Riverside"/><meta name="creator" content="Litian Gong"/><meta name="publisher" content="Litian Gong"/><meta property="og:title" content="Litian Gong"/><meta property="og:description" content="Master&#x27;s student in Electrical Engineering at UC Riverside, researching embodied AI and robot learning."/><meta property="og:site_name" content="Litian Gong&#x27;s Academic Website"/><meta property="og:locale" content="en_US"/><meta property="og:type" content="website"/><meta name="twitter:card" content="summary"/><meta name="twitter:title" content="Litian Gong"/><meta name="twitter:description" content="Master&#x27;s student in Electrical Engineering at UC Riverside, researching embodied AI and robot learning."/><link rel="icon" href="/favicon.svg"/><link rel="stylesheet" href="https://google-fonts.jialeliu.com/css2?family=Inter:wght@300;400;500;600;700&amp;family=Crimson+Text:ital,wght@0,400;0,600;1,400&amp;display=swap"/><script>
              try {
                const theme = localStorage.getItem('theme-storage');
                const parsed = theme ? JSON.parse(theme) : null;
                const setting = parsed?.state?.theme || 'system';
                const prefersDark = typeof window !== 'undefined' && window.matchMedia && window.matchMedia('(prefers-color-scheme: dark)').matches;
                const effective = setting === 'dark' ? 'dark' : (setting === 'light' ? 'light' : (prefersDark ? 'dark' : 'light'));
                var root = document.documentElement;
                root.classList.add(effective);
                root.setAttribute('data-theme', effective);
              } catch (e) {
                var root = document.documentElement;
                root.classList.add('light');
                root.setAttribute('data-theme', 'light');
              }
            </script><script src="/_next/static/chunks/a6dad97d9634a72d.js" noModule=""></script></head><body class="font-sans antialiased"><div hidden=""><!--$--><!--/$--></div><div style="visibility:hidden"><nav class="fixed top-0 left-0 right-0 z-50" data-headlessui-state=""><div class="transition-all duration-300 ease-out bg-transparent" style="transform:translateY(-100px)"><div class="max-w-7xl mx-auto px-4 sm:px-6 lg:px-8"><div class="flex justify-between items-center h-16 lg:h-20"><div class="flex-shrink-0"><a class="text-xl lg:text-2xl font-serif font-semibold text-primary hover:text-accent transition-colors duration-200 focus-visible:ring-2 focus-visible:ring-accent/50 focus-visible:ring-offset-2" href="/">Litian Gong</a></div><div class="hidden lg:block"><div class="ml-10 flex items-center space-x-8"><div class="flex items-baseline space-x-8"><a class="relative px-3 py-2 text-sm font-medium transition-all duration-200 rounded hover:bg-accent/10 hover:shadow-sm focus-visible:ring-2 focus-visible:ring-accent/50 focus-visible:ring-offset-2 text-neutral-600 hover:text-primary" href="/"><span class="relative z-10">About</span></a><a class="relative px-3 py-2 text-sm font-medium transition-all duration-200 rounded hover:bg-accent/10 hover:shadow-sm focus-visible:ring-2 focus-visible:ring-accent/50 focus-visible:ring-offset-2 text-neutral-600 hover:text-primary" href="/publications/"><span class="relative z-10">Publications</span></a><a class="relative px-3 py-2 text-sm font-medium transition-all duration-200 rounded hover:bg-accent/10 hover:shadow-sm focus-visible:ring-2 focus-visible:ring-accent/50 focus-visible:ring-offset-2 text-primary" href="/project/"><span class="relative z-10">Projects</span><div class="absolute inset-0 bg-accent/10 rounded-lg"></div></a><a class="relative px-3 py-2 text-sm font-medium transition-all duration-200 rounded hover:bg-accent/10 hover:shadow-sm focus-visible:ring-2 focus-visible:ring-accent/50 focus-visible:ring-offset-2 text-neutral-600 hover:text-primary" href="/awards/"><span class="relative z-10">Awards</span></a><a class="relative px-3 py-2 text-sm font-medium transition-all duration-200 rounded hover:bg-accent/10 hover:shadow-sm focus-visible:ring-2 focus-visible:ring-accent/50 focus-visible:ring-offset-2 text-neutral-600 hover:text-primary" href="/services/"><span class="relative z-10">Services</span></a><a class="relative px-3 py-2 text-sm font-medium transition-all duration-200 rounded hover:bg-accent/10 hover:shadow-sm focus-visible:ring-2 focus-visible:ring-accent/50 focus-visible:ring-offset-2 text-neutral-600 hover:text-primary" href="/cv/"><span class="relative z-10">CV</span></a></div><div class="flex items-center justify-center w-10 h-10 rounded-lg border border-neutral-200 dark:border-neutral-700/30 bg-background dark:bg-neutral-800"><div class="w-4 h-4 rounded-full bg-neutral-300 animate-pulse"></div></div></div></div><div class="lg:hidden flex items-center space-x-2"><div class="flex items-center justify-center w-10 h-10 rounded-lg border border-neutral-200 dark:border-neutral-700/30 bg-background dark:bg-neutral-800"><div class="w-4 h-4 rounded-full bg-neutral-300 animate-pulse"></div></div><button class="inline-flex items-center justify-center p-2 rounded-md text-neutral-600 hover:text-primary hover:bg-neutral-100 dark:hover:bg-neutral-800 focus:outline-none focus:ring-2 focus:ring-inset focus:ring-accent transition-colors duration-200" id="headlessui-disclosure-button-_R_5pdb_" type="button" aria-expanded="false" data-headlessui-state=""><span class="sr-only">Open main menu</span><div><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" class="block h-6 w-6"><path stroke-linecap="round" stroke-linejoin="round" d="M3.75 6.75h16.5M3.75 12h16.5m-16.5 5.25h16.5"></path></svg></div></button></div></div></div></div></nav><main class="min-h-screen pt-16 lg:pt-20"><div class="max-w-7xl mx-auto px-4 sm:px-6 lg:px-8 py-12"><div style="opacity:0;transform:translateY(20px)"><div class="mb-8"><h1 class="text-4xl font-serif font-bold text-primary mb-4">Projects</h1><p class="text-lg text-neutral-600 dark:text-neutral-500 max-w-2xl">Research projects and work I have been involved in.</p></div><div class="grid gap-6"><div class="bg-white dark:bg-neutral-900 p-6 rounded-xl shadow-sm border border-neutral-200 dark:border-neutral-800 hover:shadow-lg transition-all duration-200 hover:scale-[1.01] cursor-pointer" style="opacity:0;transform:translateY(20px)"><div class="flex flex-col md:flex-row gap-4"><div class="w-full md:w-48 flex-shrink-0 relative z-0"><div class="aspect-square relative rounded-lg overflow-visible dark:bg-neutral-700 group cursor-pointer"><img alt="AutoFocus-IL" loading="lazy" decoding="async" data-nimg="fill" class="object-contain p-2 transition-all duration-300 ease-in-out group-hover:scale-110 group-hover:z-[100] group-hover:shadow-2xl rounded-lg" style="position:absolute;height:100%;width:100%;left:0;top:0;right:0;bottom:0;color:transparent" src="/papers/autofocus-il.png"/></div></div><div class="flex-grow"><div class="flex justify-between items-start mb-2"><h3 class="text-xl font-semibold text-primary">AutoFocus-IL</h3><span class="text-sm text-neutral-500 font-medium bg-neutral-100 dark:bg-neutral-800 px-2 py-1 rounded">2025</span></div><p class="text-base text-accent font-medium mb-3">VLM-based Visual Imitation Learning</p><p class="text-base text-neutral-600 dark:text-neutral-500 leading-relaxed mb-3">A vision-language model guided saliency framework for data-efficient visual imitation learning. The system automatically identifies task-relevant visual cues without requiring human gaze supervision, improving policy robustness in both simulation and real-robot experiments.</p><div class="flex flex-wrap gap-2 mb-3"><a href="https://autofocus-il.github.io/" target="_blank" rel="noopener noreferrer" class="inline-flex items-center px-3 py-1 rounded-md text-xs font-medium bg-neutral-100 dark:bg-neutral-800 text-neutral-700 dark:text-neutral-300 hover:bg-accent hover:text-white transition-colors focus-visible:ring-2 focus-visible:ring-accent/50 focus-visible:ring-offset-2"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" class="h-3 w-3 mr-1.5"><path stroke-linecap="round" stroke-linejoin="round" d="M12 21a9.004 9.004 0 0 0 8.716-6.747M12 21a9.004 9.004 0 0 1-8.716-6.747M12 21c2.485 0 4.5-4.03 4.5-9S14.485 3 12 3m0 18c-2.485 0-4.5-4.03-4.5-9S9.515 3 12 3m0 0a8.997 8.997 0 0 1 7.843 4.582M12 3a8.997 8.997 0 0 0-7.843 4.582m15.686 0A11.953 11.953 0 0 1 12 10.5c-2.998 0-5.74-1.1-7.843-2.918m15.686 0A8.959 8.959 0 0 1 21 12c0 .778-.099 1.533-.284 2.253m0 0A17.919 17.919 0 0 1 12 16.5c-3.162 0-6.133-.815-8.716-2.247m0 0A9.015 9.015 0 0 1 3 12c0-1.605.42-3.113 1.157-4.418"></path></svg>Demo</a><a href="https://github.com/autofocus-il/autofocus-il" target="_blank" rel="noopener noreferrer" class="inline-flex items-center px-3 py-1 rounded-md text-xs font-medium bg-neutral-100 dark:bg-neutral-800 text-neutral-700 dark:text-neutral-300 hover:bg-accent hover:text-white transition-colors focus-visible:ring-2 focus-visible:ring-accent/50 focus-visible:ring-offset-2"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" class="h-3 w-3 mr-1.5"><path stroke-linecap="round" stroke-linejoin="round" d="M17.25 6.75 22.5 12l-5.25 5.25m-10.5 0L1.5 12l5.25-5.25m7.5-3-4.5 16.5"></path></svg>Code</a><a href="https://arxiv.org/abs/2511.18617" target="_blank" rel="noopener noreferrer" class="inline-flex items-center px-3 py-1 rounded-md text-xs font-medium bg-neutral-100 dark:bg-neutral-800 text-neutral-700 dark:text-neutral-300 hover:bg-accent hover:text-white transition-colors focus-visible:ring-2 focus-visible:ring-accent/50 focus-visible:ring-offset-2"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" class="h-3 w-3 mr-1.5"><path stroke-linecap="round" stroke-linejoin="round" d="M19.5 14.25v-2.625a3.375 3.375 0 0 0-3.375-3.375h-1.5A1.125 1.125 0 0 1 13.5 7.125v-1.5a3.375 3.375 0 0 0-3.375-3.375H8.25m0 12.75h7.5m-7.5 3H12M10.5 2.25H5.625c-.621 0-1.125.504-1.125 1.125v17.25c0 .621.504 1.125 1.125 1.125h12.75c.621 0 1.125-.504 1.125-1.125V11.25a9 9 0 0 0-9-9Z"></path></svg>Paper</a></div><div class="flex flex-wrap gap-2 mt-4"><span class="text-xs text-neutral-500 bg-neutral-50 dark:bg-neutral-800/50 px-2 py-1 rounded border border-neutral-100 dark:border-neutral-800">Imitation Learning</span><span class="text-xs text-neutral-500 bg-neutral-50 dark:bg-neutral-800/50 px-2 py-1 rounded border border-neutral-100 dark:border-neutral-800">VLMs</span><span class="text-xs text-neutral-500 bg-neutral-50 dark:bg-neutral-800/50 px-2 py-1 rounded border border-neutral-100 dark:border-neutral-800">Robot Learning</span><span class="text-xs text-neutral-500 bg-neutral-50 dark:bg-neutral-800/50 px-2 py-1 rounded border border-neutral-100 dark:border-neutral-800">PyTorch</span></div></div></div></div><div class="bg-white dark:bg-neutral-900 p-6 rounded-xl shadow-sm border border-neutral-200 dark:border-neutral-800 hover:shadow-lg transition-all duration-200 hover:scale-[1.01] cursor-pointer" style="opacity:0;transform:translateY(20px)"><div class="flex flex-col md:flex-row gap-4"><div class="w-full md:w-48 flex-shrink-0 relative z-0"><div class="aspect-square relative rounded-lg overflow-visible dark:bg-neutral-700 group cursor-pointer"><img alt="ORIC Benchmark" loading="lazy" decoding="async" data-nimg="fill" class="object-contain p-2 transition-all duration-300 ease-in-out group-hover:scale-110 group-hover:z-[100] group-hover:shadow-2xl rounded-lg" style="position:absolute;height:100%;width:100%;left:0;top:0;right:0;bottom:0;color:transparent" src="/papers/oric.png"/></div></div><div class="flex-grow"><div class="flex justify-between items-start mb-2"><h3 class="text-xl font-semibold text-primary">ORIC Benchmark</h3><span class="text-sm text-neutral-500 font-medium bg-neutral-100 dark:bg-neutral-800 px-2 py-1 rounded">2025</span></div><p class="text-base text-accent font-medium mb-3">Object Recognition in Incongruous Contexts</p><p class="text-base text-neutral-600 dark:text-neutral-500 leading-relaxed mb-3">A comprehensive benchmark for evaluating object recognition capabilities of large vision-language models when objects appear in unexpected or unusual settings. The benchmark tests robustness and generalization of VLMs across diverse contextual scenarios.</p><div class="flex flex-wrap gap-2 mb-3"><a href="https://github.com/ZhaoyangLi-1/ORIC" target="_blank" rel="noopener noreferrer" class="inline-flex items-center px-3 py-1 rounded-md text-xs font-medium bg-neutral-100 dark:bg-neutral-800 text-neutral-700 dark:text-neutral-300 hover:bg-accent hover:text-white transition-colors focus-visible:ring-2 focus-visible:ring-accent/50 focus-visible:ring-offset-2"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" class="h-3 w-3 mr-1.5"><path stroke-linecap="round" stroke-linejoin="round" d="M17.25 6.75 22.5 12l-5.25 5.25m-10.5 0L1.5 12l5.25-5.25m7.5-3-4.5 16.5"></path></svg>Code</a><a href="https://arxiv.org/abs/2509.15695" target="_blank" rel="noopener noreferrer" class="inline-flex items-center px-3 py-1 rounded-md text-xs font-medium bg-neutral-100 dark:bg-neutral-800 text-neutral-700 dark:text-neutral-300 hover:bg-accent hover:text-white transition-colors focus-visible:ring-2 focus-visible:ring-accent/50 focus-visible:ring-offset-2"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" class="h-3 w-3 mr-1.5"><path stroke-linecap="round" stroke-linejoin="round" d="M19.5 14.25v-2.625a3.375 3.375 0 0 0-3.375-3.375h-1.5A1.125 1.125 0 0 1 13.5 7.125v-1.5a3.375 3.375 0 0 0-3.375-3.375H8.25m0 12.75h7.5m-7.5 3H12M10.5 2.25H5.625c-.621 0-1.125.504-1.125 1.125v17.25c0 .621.504 1.125 1.125 1.125h12.75c.621 0 1.125-.504 1.125-1.125V11.25a9 9 0 0 0-9-9Z"></path></svg>Paper</a></div><div class="flex flex-wrap gap-2 mt-4"><span class="text-xs text-neutral-500 bg-neutral-50 dark:bg-neutral-800/50 px-2 py-1 rounded border border-neutral-100 dark:border-neutral-800">Computer Vision</span><span class="text-xs text-neutral-500 bg-neutral-50 dark:bg-neutral-800/50 px-2 py-1 rounded border border-neutral-100 dark:border-neutral-800">VLMs</span><span class="text-xs text-neutral-500 bg-neutral-50 dark:bg-neutral-800/50 px-2 py-1 rounded border border-neutral-100 dark:border-neutral-800">Benchmarking</span><span class="text-xs text-neutral-500 bg-neutral-50 dark:bg-neutral-800/50 px-2 py-1 rounded border border-neutral-100 dark:border-neutral-800">Evaluation</span></div></div></div></div></div></div></div><!--$--><!--/$--></main><footer class="border-t border-neutral-200/50 bg-neutral-50/50 dark:bg-neutral-900/50 dark:border-neutral-700/50"><div class="max-w-7xl mx-auto px-4 sm:px-6 lg:px-8 py-6"><div class="flex flex-col sm:flex-row justify-between items-center gap-2"><p class="text-xs text-neutral-500">Last updated: <!-- -->February 21, 2026</p><p class="text-xs text-neutral-500 flex items-center"><a href="https://github.com/xyjoey/PRISM" target="_blank" rel="noopener noreferrer" class="cursor-pointer transition-colors hover:text-accent">Built with PRISM<svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-rocket inline ml-1.5 h-3.5 w-3.5" aria-hidden="true"><path d="M4.5 16.5c-1.5 1.26-2 5-2 5s3.74-.5 5-2c.71-.84.7-2.13-.09-2.91a2.18 2.18 0 0 0-2.91-.09z"></path><path d="m12 15-3-3a22 22 0 0 1 2-3.95A12.88 12.88 0 0 1 22 2c0 2.72-.78 7.5-6 11a22.35 22.35 0 0 1-4 2z"></path><path d="M9 12H4s.55-3.03 2-4c1.62-1.08 5 0 5 0"></path><path d="M12 15v5s3.03-.55 4-2c1.08-1.62 0-5 0-5"></path></svg></a></p></div></div></footer></div><script src="/_next/static/chunks/15f134bf6a9ffc0d.js" id="_R_" async=""></script><script>(self.__next_f=self.__next_f||[]).push([0])</script><script>self.__next_f.push([1,"1:\"$Sreact.fragment\"\n2:I[94519,[\"/_next/static/chunks/9c176f40581040da.js\",\"/_next/static/chunks/96325a1b41eead81.js\",\"/_next/static/chunks/0137a57162bf5a2a.js\"],\"ThemeProvider\"]\n3:I[28127,[\"/_next/static/chunks/9c176f40581040da.js\",\"/_next/static/chunks/96325a1b41eead81.js\",\"/_next/static/chunks/0137a57162bf5a2a.js\"],\"default\"]\n4:I[39756,[\"/_next/static/chunks/ff1a16fafef87110.js\",\"/_next/static/chunks/694836347d1e5ef3.js\"],\"default\"]\n5:I[37457,[\"/_next/static/chunks/ff1a16fafef87110.js\",\"/_next/static/chunks/694836347d1e5ef3.js\"],\"default\"]\n6:I[58234,[\"/_next/static/chunks/9c176f40581040da.js\",\"/_next/static/chunks/96325a1b41eead81.js\",\"/_next/static/chunks/0137a57162bf5a2a.js\"],\"default\"]\na:I[68027,[\"/_next/static/chunks/ff1a16fafef87110.js\",\"/_next/static/chunks/694836347d1e5ef3.js\"],\"default\"]\n:HL[\"/_next/static/chunks/33fe7063c635829e.css\",\"style\"]\n:HL[\"https://google-fonts.jialeliu.com/css2?family=Inter:wght@300;400;500;600;700\u0026family=Crimson+Text:ital,wght@0,400;0,600;1,400\u0026display=swap\",\"style\"]\n"])</script><script>self.__next_f.push([1,"0:{\"P\":null,\"b\":\"eJmAS4bSgJUF5hZPCAqBJ\",\"c\":[\"\",\"project\",\"\"],\"q\":\"\",\"i\":false,\"f\":[[[\"\",{\"children\":[[\"slug\",\"project\",\"d\"],{\"children\":[\"__PAGE__\",{}]}]},\"$undefined\",\"$undefined\",true],[[\"$\",\"$1\",\"c\",{\"children\":[[[\"$\",\"link\",\"0\",{\"rel\":\"stylesheet\",\"href\":\"/_next/static/chunks/33fe7063c635829e.css\",\"precedence\":\"next\",\"crossOrigin\":\"$undefined\",\"nonce\":\"$undefined\"}],[\"$\",\"script\",\"script-0\",{\"src\":\"/_next/static/chunks/9c176f40581040da.js\",\"async\":true,\"nonce\":\"$undefined\"}],[\"$\",\"script\",\"script-1\",{\"src\":\"/_next/static/chunks/96325a1b41eead81.js\",\"async\":true,\"nonce\":\"$undefined\"}],[\"$\",\"script\",\"script-2\",{\"src\":\"/_next/static/chunks/0137a57162bf5a2a.js\",\"async\":true,\"nonce\":\"$undefined\"}]],[\"$\",\"html\",null,{\"lang\":\"en\",\"className\":\"scroll-smooth\",\"suppressHydrationWarning\":true,\"children\":[[\"$\",\"head\",null,{\"children\":[[\"$\",\"link\",null,{\"rel\":\"icon\",\"href\":\"/favicon.svg\",\"type\":\"image/svg+xml\"}],[\"$\",\"link\",null,{\"rel\":\"dns-prefetch\",\"href\":\"https://google-fonts.jialeliu.com\"}],[\"$\",\"link\",null,{\"rel\":\"preconnect\",\"href\":\"https://google-fonts.jialeliu.com\",\"crossOrigin\":\"\"}],[\"$\",\"link\",null,{\"rel\":\"stylesheet\",\"href\":\"https://google-fonts.jialeliu.com/css2?family=Inter:wght@300;400;500;600;700\u0026family=Crimson+Text:ital,wght@0,400;0,600;1,400\u0026display=swap\"}],[\"$\",\"script\",null,{\"dangerouslySetInnerHTML\":{\"__html\":\"\\n              try {\\n                const theme = localStorage.getItem('theme-storage');\\n                const parsed = theme ? JSON.parse(theme) : null;\\n                const setting = parsed?.state?.theme || 'system';\\n                const prefersDark = typeof window !== 'undefined' \u0026\u0026 window.matchMedia \u0026\u0026 window.matchMedia('(prefers-color-scheme: dark)').matches;\\n                const effective = setting === 'dark' ? 'dark' : (setting === 'light' ? 'light' : (prefersDark ? 'dark' : 'light'));\\n                var root = document.documentElement;\\n                root.classList.add(effective);\\n                root.setAttribute('data-theme', effective);\\n              } catch (e) {\\n                var root = document.documentElement;\\n                root.classList.add('light');\\n                root.setAttribute('data-theme', 'light');\\n              }\\n            \"}}]]}],[\"$\",\"body\",null,{\"className\":\"font-sans antialiased\",\"children\":[\"$\",\"$L2\",null,{\"children\":[[\"$\",\"$L3\",null,{\"items\":[{\"title\":\"About\",\"type\":\"page\",\"target\":\"about\",\"href\":\"/\"},{\"title\":\"Publications\",\"type\":\"page\",\"target\":\"publications\",\"href\":\"/publications\"},{\"title\":\"Projects\",\"type\":\"page\",\"target\":\"project\",\"href\":\"/project\"},{\"title\":\"Awards\",\"type\":\"page\",\"target\":\"awards\",\"href\":\"/awards\"},{\"title\":\"Services\",\"type\":\"page\",\"target\":\"services\",\"href\":\"/services\"},{\"title\":\"CV\",\"type\":\"page\",\"target\":\"cv\",\"href\":\"/cv\"}],\"siteTitle\":\"Litian Gong\",\"enableOnePageMode\":false}],[\"$\",\"main\",null,{\"className\":\"min-h-screen pt-16 lg:pt-20\",\"children\":[\"$\",\"$L4\",null,{\"parallelRouterKey\":\"children\",\"error\":\"$undefined\",\"errorStyles\":\"$undefined\",\"errorScripts\":\"$undefined\",\"template\":[\"$\",\"$L5\",null,{}],\"templateStyles\":\"$undefined\",\"templateScripts\":\"$undefined\",\"notFound\":[[[\"$\",\"title\",null,{\"children\":\"404: This page could not be found.\"}],[\"$\",\"div\",null,{\"style\":{\"fontFamily\":\"system-ui,\\\"Segoe UI\\\",Roboto,Helvetica,Arial,sans-serif,\\\"Apple Color Emoji\\\",\\\"Segoe UI Emoji\\\"\",\"height\":\"100vh\",\"textAlign\":\"center\",\"display\":\"flex\",\"flexDirection\":\"column\",\"alignItems\":\"center\",\"justifyContent\":\"center\"},\"children\":[\"$\",\"div\",null,{\"children\":[[\"$\",\"style\",null,{\"dangerouslySetInnerHTML\":{\"__html\":\"body{color:#000;background:#fff;margin:0}.next-error-h1{border-right:1px solid rgba(0,0,0,.3)}@media (prefers-color-scheme:dark){body{color:#fff;background:#000}.next-error-h1{border-right:1px solid rgba(255,255,255,.3)}}\"}}],[\"$\",\"h1\",null,{\"className\":\"next-error-h1\",\"style\":{\"display\":\"inline-block\",\"margin\":\"0 20px 0 0\",\"padding\":\"0 23px 0 0\",\"fontSize\":24,\"fontWeight\":500,\"verticalAlign\":\"top\",\"lineHeight\":\"49px\"},\"children\":404}],[\"$\",\"div\",null,{\"style\":{\"display\":\"inline-block\"},\"children\":[\"$\",\"h2\",null,{\"style\":{\"fontSize\":14,\"fontWeight\":400,\"lineHeight\":\"49px\",\"margin\":0},\"children\":\"This page could not be found.\"}]}]]}]}]],[]],\"forbidden\":\"$undefined\",\"unauthorized\":\"$undefined\"}]}],[\"$\",\"$L6\",null,{\"lastUpdated\":\"February 21, 2026\"}]]}]}]]}]]}],{\"children\":[[\"$\",\"$1\",\"c\",{\"children\":[null,[\"$\",\"$L4\",null,{\"parallelRouterKey\":\"children\",\"error\":\"$undefined\",\"errorStyles\":\"$undefined\",\"errorScripts\":\"$undefined\",\"template\":\"$L7\",\"templateStyles\":\"$undefined\",\"templateScripts\":\"$undefined\",\"notFound\":\"$undefined\",\"forbidden\":\"$undefined\",\"unauthorized\":\"$undefined\"}]]}],{\"children\":[\"$L8\",{},null,false,false]},null,false,false]},null,false,false],\"$L9\",false]],\"m\":\"$undefined\",\"G\":[\"$a\",[]],\"S\":true}\n"])</script><script>self.__next_f.push([1,"c:I[97367,[\"/_next/static/chunks/ff1a16fafef87110.js\",\"/_next/static/chunks/694836347d1e5ef3.js\"],\"OutletBoundary\"]\nd:\"$Sreact.suspense\"\nf:I[97367,[\"/_next/static/chunks/ff1a16fafef87110.js\",\"/_next/static/chunks/694836347d1e5ef3.js\"],\"ViewportBoundary\"]\n11:I[97367,[\"/_next/static/chunks/ff1a16fafef87110.js\",\"/_next/static/chunks/694836347d1e5ef3.js\"],\"MetadataBoundary\"]\n7:[\"$\",\"$L5\",null,{}]\n8:[\"$\",\"$1\",\"c\",{\"children\":[\"$Lb\",[[\"$\",\"script\",\"script-0\",{\"src\":\"/_next/static/chunks/9f31ef4f69e03b59.js\",\"async\":true,\"nonce\":\"$undefined\"}],[\"$\",\"script\",\"script-1\",{\"src\":\"/_next/static/chunks/35851190b7d05ff5.js\",\"async\":true,\"nonce\":\"$undefined\"}]],[\"$\",\"$Lc\",null,{\"children\":[\"$\",\"$d\",null,{\"name\":\"Next.MetadataOutlet\",\"children\":\"$@e\"}]}]]}]\n9:[\"$\",\"$1\",\"h\",{\"children\":[null,[\"$\",\"$Lf\",null,{\"children\":\"$L10\"}],[\"$\",\"div\",null,{\"hidden\":true,\"children\":[\"$\",\"$L11\",null,{\"children\":[\"$\",\"$d\",null,{\"name\":\"Next.Metadata\",\"children\":\"$L12\"}]}]}],null]}]\n"])</script><script>self.__next_f.push([1,"13:I[36610,[\"/_next/static/chunks/9c176f40581040da.js\",\"/_next/static/chunks/96325a1b41eead81.js\",\"/_next/static/chunks/0137a57162bf5a2a.js\",\"/_next/static/chunks/9f31ef4f69e03b59.js\",\"/_next/static/chunks/35851190b7d05ff5.js\"],\"default\"]\n"])</script><script>self.__next_f.push([1,"b:[\"$\",\"div\",null,{\"className\":\"max-w-7xl mx-auto px-4 sm:px-6 lg:px-8 py-12\",\"children\":[false,false,[\"$\",\"$L13\",null,{\"config\":{\"type\":\"card\",\"title\":\"Projects\",\"description\":\"Research projects and work I have been involved in.\",\"items\":[{\"title\":\"AutoFocus-IL\",\"subtitle\":\"VLM-based Visual Imitation Learning\",\"date\":\"2025\",\"content\":\"A vision-language model guided saliency framework for data-efficient visual imitation learning. The system automatically identifies task-relevant visual cues without requiring human gaze supervision, improving policy robustness in both simulation and real-robot experiments.\",\"image\":\"/papers/autofocus-il.png\",\"demo\":\"https://autofocus-il.github.io/\",\"code\":\"https://github.com/autofocus-il/autofocus-il\",\"paper\":\"https://arxiv.org/abs/2511.18617\",\"tags\":[\"Imitation Learning\",\"VLMs\",\"Robot Learning\",\"PyTorch\"]},{\"title\":\"ORIC Benchmark\",\"subtitle\":\"Object Recognition in Incongruous Contexts\",\"date\":\"2025\",\"content\":\"A comprehensive benchmark for evaluating object recognition capabilities of large vision-language models when objects appear in unexpected or unusual settings. The benchmark tests robustness and generalization of VLMs across diverse contextual scenarios.\",\"image\":\"/papers/oric.png\",\"code\":\"https://github.com/ZhaoyangLi-1/ORIC\",\"paper\":\"https://arxiv.org/abs/2509.15695\",\"tags\":[\"Computer Vision\",\"VLMs\",\"Benchmarking\",\"Evaluation\"]}]}}]]}]\n"])</script><script>self.__next_f.push([1,"10:[[\"$\",\"meta\",\"0\",{\"charSet\":\"utf-8\"}],[\"$\",\"meta\",\"1\",{\"name\":\"viewport\",\"content\":\"width=device-width, initial-scale=1\"}]]\n"])</script><script>self.__next_f.push([1,"14:I[27201,[\"/_next/static/chunks/ff1a16fafef87110.js\",\"/_next/static/chunks/694836347d1e5ef3.js\"],\"IconMark\"]\ne:null\n12:[[\"$\",\"title\",\"0\",{\"children\":\"Projects | Litian Gong\"}],[\"$\",\"meta\",\"1\",{\"name\":\"description\",\"content\":\"Research projects and work I have been involved in.\"}],[\"$\",\"meta\",\"2\",{\"name\":\"author\",\"content\":\"Litian Gong\"}],[\"$\",\"meta\",\"3\",{\"name\":\"keywords\",\"content\":\"Litian Gong,PhD,Research,University of California, Riverside\"}],[\"$\",\"meta\",\"4\",{\"name\":\"creator\",\"content\":\"Litian Gong\"}],[\"$\",\"meta\",\"5\",{\"name\":\"publisher\",\"content\":\"Litian Gong\"}],[\"$\",\"meta\",\"6\",{\"property\":\"og:title\",\"content\":\"Litian Gong\"}],[\"$\",\"meta\",\"7\",{\"property\":\"og:description\",\"content\":\"Master's student in Electrical Engineering at UC Riverside, researching embodied AI and robot learning.\"}],[\"$\",\"meta\",\"8\",{\"property\":\"og:site_name\",\"content\":\"Litian Gong's Academic Website\"}],[\"$\",\"meta\",\"9\",{\"property\":\"og:locale\",\"content\":\"en_US\"}],[\"$\",\"meta\",\"10\",{\"property\":\"og:type\",\"content\":\"website\"}],[\"$\",\"meta\",\"11\",{\"name\":\"twitter:card\",\"content\":\"summary\"}],[\"$\",\"meta\",\"12\",{\"name\":\"twitter:title\",\"content\":\"Litian Gong\"}],[\"$\",\"meta\",\"13\",{\"name\":\"twitter:description\",\"content\":\"Master's student in Electrical Engineering at UC Riverside, researching embodied AI and robot learning.\"}],[\"$\",\"link\",\"14\",{\"rel\":\"icon\",\"href\":\"/favicon.svg\"}],[\"$\",\"$L14\",\"15\",{}]]\n"])</script></body></html>